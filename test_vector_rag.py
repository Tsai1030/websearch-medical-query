# -*- coding: utf-8 -*-
import sys
import os

# è¨­å®š UTF-8 ç·¨ç¢¼
if sys.platform.startswith('win'):
    # Windows ç’°å¢ƒä¸‹è¨­å®šæŽ§åˆ¶å°ç·¨ç¢¼
    os.system('chcp 65001 > nul')
    # é‡æ–°è¨­å®š stdout å’Œ stderr ç·¨ç¢¼
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())

import chromadb
from sentence_transformers import SentenceTransformer
import json

def test_vector_rag():
    print("ðŸ§ª æ¸¬è©¦å‘é‡ RAG æª¢ç´¢åŠŸèƒ½")
    print("=" * 50)
    
    try:
        # 1. åˆå§‹åŒ–æ¨¡åž‹å’Œè³‡æ–™åº«
        print("ðŸ”§ åˆå§‹åŒ–æ¨¡åž‹å’Œè³‡æ–™åº«...")
        model = SentenceTransformer('BAAI/bge-m3')
        client = chromadb.PersistentClient(path="chroma_db/doctorv1")
        collection = client.get_or_create_collection("doctorv1")
        
        # 2. è¼‰å…¥åŽŸå§‹é†«å¸«è³‡æ–™ï¼ˆç”¨æ–¼æ¯”å°ï¼‰
        with open('doctors.json', 'r', encoding='utf-8') as f:
            doctors = json.load(f)
        
        print(f"âœ… æˆåŠŸè¼‰å…¥ {len(doctors)} ä½é†«å¸«è³‡æ–™")
        
        # 3. æ¸¬è©¦æŸ¥è©¢æ¡ˆä¾‹
        test_queries = [
            {
                "query": "é«˜é†«æœ±å¿—ç”Ÿé†«å¸«çš„å°ˆé•·æ˜¯ä»€éº¼ï¼Ÿ",
                "expected": "æœ±å¿—ç”Ÿ",
                "description": "é†«å¸«å§“åæŸ¥è©¢"
            },
            {
                "query": "å¿ƒè‡Ÿé›»æ°£ç”Ÿç†å­¸å°ˆå®¶",
                "expected": "å¿ƒè‡Ÿé›»æ°£ç”Ÿç†å­¸",
                "description": "å°ˆé•·é—œéµå­—æŸ¥è©¢"
            },
            {
                "query": "é«˜è¡€å£“æ²»ç™‚é†«å¸«",
                "expected": "é«˜è¡€å£“",
                "description": "ç–¾ç—…é—œéµå­—æŸ¥è©¢"
            },
            {
                "query": "é«˜é›„é†«å­¸å¤§å­¸å¿ƒè‡Ÿè¡€ç®¡å…§ç§‘ä¸»æ²»é†«å¸«",
                "expected": "å¿ƒè‡Ÿè¡€ç®¡å…§ç§‘",
                "description": "ç§‘åˆ¥å’Œè·ç¨±æŸ¥è©¢"
            },
            {
                "query": "ä»‹å…¥æ€§å¿ƒå°Žç®¡æ²»ç™‚å°ˆå®¶",
                "expected": "ä»‹å…¥æ€§å¿ƒå°Žç®¡æ²»ç™‚",
                "description": "æ²»ç™‚æŠ€è¡“æŸ¥è©¢"
            }
        ]
        
        print(f"\nðŸ” é–‹å§‹æ¸¬è©¦ {len(test_queries)} å€‹æŸ¥è©¢æ¡ˆä¾‹...")
        
        for i, test_case in enumerate(test_queries, 1):
            print(f"\n æ¸¬è©¦ {i}: {test_case['description']}")
            print(f"æŸ¥è©¢: \"{test_case['query']}\"")
            
            # åŸ·è¡Œå‘é‡æª¢ç´¢
            query_vec = model.encode(test_case['query'])
            results = collection.query(
                query_embeddings=[query_vec.tolist()], 
                n_results=3
            )
            
            # é¡¯ç¤ºçµæžœ
            print("ðŸ” æª¢ç´¢çµæžœ:")
            for j, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):
                print(f"  {j+1}. ç›¸ä¼¼åº¦: {1-distance:.3f}")
                print(f"     å…§å®¹: {doc[:100]}...")
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«é æœŸå…§å®¹
                if test_case['expected'].lower() in doc.lower():
                    print(f"     âœ… åŒ…å«é æœŸå…§å®¹: {test_case['expected']}")
                else:
                    print(f"     âš ï¸ æœªåŒ…å«é æœŸå…§å®¹: {test_case['expected']}")
            
            print("-" * 40)
        
        # 4. æ¸¬è©¦è³‡æ–™åº«çµ±è¨ˆ
        print("\nðŸ“Š è³‡æ–™åº«çµ±è¨ˆ:")
        print(f"ç¸½é†«å¸«æ•¸é‡: {len(doctors)}")
        print(f"å‘é‡è³‡æ–™åº«å¤§å°: {collection.count()} ç­†")
        
        # 5. æ¸¬è©¦ç›¸ä¼¼åº¦æŽ’åº
        print("\n æ¸¬è©¦ç›¸ä¼¼åº¦æŽ’åº:")
        query = "å¿ƒè‡Ÿè¡€ç®¡ç–¾ç—…å°ˆå®¶"
        query_vec = model.encode(query)
        results = collection.query(
            query_embeddings=[query_vec.tolist()], 
            n_results=5
        )
        
        print(f"æŸ¥è©¢: \"{query}\"")
        for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):
            similarity = 1 - distance
            print(f"  {i+1}. ç›¸ä¼¼åº¦: {similarity:.3f}")
            # æå–é†«å¸«å§“å
            doctor_name = doc.split('ï¼Œ')[0] if 'ï¼Œ' in doc else doc[:10]
            print(f"     é†«å¸«: {doctor_name}")
        
        print("\nâœ… å‘é‡ RAG æ¸¬è©¦å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
        return False

def test_single_query(query):
    """æ¸¬è©¦å–®ä¸€æŸ¥è©¢"""
    print(f" æ¸¬è©¦å–®ä¸€æŸ¥è©¢: \"{query}\"")
    print("-" * 40)
    
    try:
        model = SentenceTransformer('BAAI/bge-m3')
        client = chromadb.PersistentClient(path="chroma_db/doctorv1")
        collection = client.get_or_create_collection("doctorv1")
        
        query_vec = model.encode(query)
        results = collection.query(
            query_embeddings=[query_vec.tolist()], 
            n_results=3
        )
        
        print("ðŸ” æª¢ç´¢çµæžœ:")
        for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):
            similarity = 1 - distance
            print(f"\n{i+1}. ç›¸ä¼¼åº¦: {similarity:.3f}")
            print(f"å®Œæ•´å…§å®¹: {doc}")
            
        return True
        
    except Exception as e:
        print(f"âŒ æŸ¥è©¢å¤±æ•—: {str(e)}")
        return False

if __name__ == "__main__":
    if len(sys.argv) > 1:
        # æ¸¬è©¦å–®ä¸€æŸ¥è©¢
        query = " ".join(sys.argv[1:])
        test_single_query(query)
    else:
        # åŸ·è¡Œå®Œæ•´æ¸¬è©¦
        test_vector_rag()